% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CTDS.R
\name{ct_fit_ds}
\alias{ct_fit_ds}
\title{Fit detection functions and estimate density/abundance}
\usage{
ct_fit_ds(
  data,
  estimate = c("density", "abundance"),
  cutpoints = NULL,
  truncation = set_truncation(data = data, cutpoints = cutpoints),
  formula = ~1,
  key = c("hn", "hr", "unif"),
  adjustment = c("cos", "herm", "poly"),
  nadj = NULL,
  order = NULL,
  select_model = FALSE,
  model_params = list(key = list("hn", "hr", "unif"), adjustment = list("cos", "herm",
    "poly"), nadj = list(0, 1, 2), order = NULL),
  field_of_view = 42,
  availability,
  n_bootstrap = 100,
  n_cores = 1,
  ...
)
}
\arguments{
\item{data}{A data frame containing distance sampling observations. Must include
columns for distance measurements and can include covariates for detection function modeling.
See \link[Distance:flatfile]{Distance::flatfile} for details.}

\item{estimate}{Character string specifying the parameter to estimate. Either
\code{"density"} (animals per km^2) or \code{"abundance"} (total number of animals). Default is \code{"density"}.}

\item{cutpoints}{if the data are binned, this vector gives the cutpoints of
the bins. Supplying a distance column in your data and specifying cutpoints
is the recommended approach for all standard binned analyses.
Ensure that the first element is 0 (or the left truncation
distance) and the last is the distance to the end of the furthest bin.
(Default \code{NULL}, no binning.) If you have provided \code{distbegin} and \code{distend}
columns in your data (note this should only be used when your cutpoints
are not constant across all your data, e.g. planes flying at differing
altitudes) then do not specify the cutpoints argument as this will cause
the \code{distbegin} and \code{distend} columns in your data to be overwritten.}

\item{truncation}{either truncation distance (numeric, e.g. 5) or percentage
(as a string, e.g. "15\%"). Can be supplied as a \code{list} with elements \code{left}
and \code{right} if left truncation is required (e.g.  \code{list(left=1,right=20)} or
\code{list(left="1\%",right="15\%")} or even \code{list(left="1",right="15\%")}).  By
default for exact distances the maximum observed distance is used as the
right truncation. When the data is binned, the right truncation is the
largest bin end point. Default left truncation is set to zero.}

\item{formula}{formula for the scale parameter. For a CDS analysis leave
this as its default \code{~1}.}

\item{key}{key function to use; \code{"hn"} gives half-normal (default), \code{"hr"}
gives hazard-rate and \code{"unif"} gives uniform. Note that if uniform key is
used, covariates cannot be included in the model.}

\item{adjustment}{adjustment terms to use; \code{"cos"} gives cosine (default),
\code{"herm"} gives Hermite polynomial and \code{"poly"} gives simple polynomial. A
value of \code{NULL} indicates that no adjustments are to be fitted.}

\item{nadj}{the number of adjustment terms to fit. In the absence of
covariates in the formula, the default value (\code{NULL}) will select via AIC
(using a sequential forward selection algorithm) up to \code{max.adjustment}
adjustments (unless \code{order} is specified). When covariates are present
in the model formula, the default value of \code{NULL} results in no adjustment
terms being fitted in the model. A non-negative integer value will cause
the specified number of adjustments to be fitted. Supplying an integer
value will allow the use of adjustment terms in addition to specifying
covariates in the model. The order of adjustment terms used will depend
on the \code{key}and \code{adjustment}. For \code{key="unif"}, adjustments of order
1, 2, 3, ... are fitted when \code{adjustment = "cos"} and order 2, 4, 6, ...
otherwise. For \code{key="hn"} or \code{"hr"} adjustments of order 2, 3, 4, ... are
fitted when \code{adjustment = "cos"} and order 4, 6, 8, ... otherwise. See
Buckland et al. (2001, p. 47) for details.}

\item{order}{order of adjustment terms to fit. The default value (\code{NULL})
results in \code{ds} choosing the orders to use - see \code{nadj}. Otherwise a scalar
positive integer value can be used to fit a single adjustment term of the
specified order, and a vector of positive integers to fit multiple
adjustment terms of the specified orders. For simple and Hermite polynomial
adjustments, only even orders are allowed. The number of adjustment terms
specified here must match \code{nadj} (or \code{nadj} can be the default \code{NULL} value).}

\item{select_model}{Logical. If \code{TRUE}, performs automated model selection
using the procedure in Howe et al. (2019). If \code{FALSE} (default),
fits a single model with specified parameters. When \code{TRUE}, \code{model_param}
defines the candidate model set.}

\item{model_params}{Named list defining candidate models for selection when
\code{select_model = TRUE}. Elements can include:
\itemize{
\item \code{key} - List of key functions to test
\item \code{adjustment} - List of adjustment types
\item \code{nadj} - List of adjustment term numbers
\item \code{order} - List vector of adjustment orders (must match \code{nadj})
}}

\item{field_of_view}{Numeric. Camera field of view angle in degrees. Default is 42 deg,
ued to calculate the sampling fraction.}

\item{availability}{A list containing availability rate corrections (output from
\code{\link[=ct_availability]{ct_availability()}}). Must include elements availability rate (0-1) and/or
standard error of availability rate}

\item{n_bootstrap}{Integer. Number of bootstrap replicates for variance estimation
of density/abundance. Default is 100. Larger values provide more precise
confidence intervals but increase computation time.}

\item{n_cores}{Integer. Number of CPU cores to use for parallel bootstrap computation.
Default is 1.}

\item{...}{
  Arguments passed on to \code{\link[Distance:ds]{Distance::ds}}
  \describe{
    \item{\code{scale}}{the scale by which the distances in the adjustment terms are
divided. Defaults to \code{"width"}, scaling by the truncation distance. If the
key is uniform only \code{"width"} will be used. The other option is \code{"scale"}:
the scale parameter of the detection}
    \item{\code{dht_group}}{should density abundance estimates consider all groups to
be size 1 (abundance of groups) \code{dht_group=TRUE} or should the abundance of
individuals (group size is taken into account), \code{dht_group=FALSE}. Default
is \code{FALSE} (abundance of individuals is calculated).}
    \item{\code{monotonicity}}{should the detection function be constrained for
monotonicity weakly (\code{"weak"}), strictly (\code{"strict"}) or not at all
(\code{"none"} or \code{FALSE}). See Monotonicity, below. (Default \code{"strict"}). By
default it is on for models without covariates in the detection function,
off when covariates are present.}
    \item{\code{method}}{optimization method to use (any method usable by
\code{\link[stats:optim]{optim}} or \code{\link[optimx:optimx]{optimx}}). Defaults to
\code{"nlminb"}.}
    \item{\code{mono_method}}{optimization method to use when monotonicity is enforced.
Can be either \code{slsqp} or \code{solnp}. Defaults to \code{slsqp}.}
    \item{\code{initial_values}}{a \code{list} of named starting values, see
\code{\link[mrds:mrds_opt]{mrds_opt}}. Only allowed when AIC term selection is not
used.}
    \item{\code{max_adjustments}}{maximum number of adjustments to try (default 5) only
used when \code{order=NULL}.}
    \item{\code{er_method}}{encounter rate variance calculation: default = 2 gives the
method of Innes et al, using expected counts in the encounter rate. Setting
to 1 gives observed counts (which matches Distance for Windows) and 0 uses
binomial variance (only useful in the rare situation where study area =
surveyed area). See \code{\link[mrds:dht.se]{dht.se}} for more details.}
    \item{\code{dht_se}}{should uncertainty be calculated when using \code{dht}? Safe to
leave as \code{TRUE}, used in \code{bootdht}.}
    \item{\code{optimizer}}{By default this is set to 'both'. In this case
the R optimizer will be used and if present the MCDS optimizer will also
be used. The result with the best likelihood value will be selected. To
run only a specified optimizer set this value to either 'R' or 'MCDS'.
See \code{\link[mrds:mcds_dot_exe]{mcds_dot_exe}} for setup instructions.}
    \item{\code{winebin}}{If you are trying to use our MCDS.exe optimizer on a
non-windows system then you may need to specify the winebin. Please
see \code{\link[mrds:mcds_dot_exe]{mcds_dot_exe}} for more details.}
  }}
}
\value{
A named list containing:
A list containing:
\itemize{
\item \code{QAIC}: (Only if \code{select_model = TRUE}) QAIC comparison table.
\item \code{Chi2}: (Only if \code{select_model = TRUE}) Chi-squared goodness-of-fit comparison.
\item \code{best_model}: The best fitted detection function model selected.
\item \code{rho}: Estimated effective detection radius (in meters).
\item \code{density} or \code{abundance}: A tibble with density or abundance estimates containing:
\code{median}, \code{mean}, \code{se}: standard error, \code{lcl}: lower confidence limit,
\code{ucl}: upper confidence limit
}
}
\description{
\code{ct_fit_ds} fits detection functions to camera trap distance sampling data and estimates
animal density or abundance using bootstrap variance estimation. Supports both
single model fitting and automated model selection procedures.
}
\section{Truncation}{


The right truncation point is by default set to be largest observed distance
or bin end point. This is a default will not be appropriate for all data and
can often be the cause of model convergence failures. It is recommended that
one plots a histogram of the observed distances prior to model fitting so as
to get a feel for an appropriate truncation distance. (Similar arguments go
for left truncation, if appropriate). Buckland et al (2001) provide
guidelines on truncation.

When specified as a percentage, the largest \code{right} and smallest \code{left}
percent distances are discarded. Percentages cannot be supplied when using
binned data.

For left truncation, there are two options: (1) fit a detection function to
the truncated data as is (this is what happens when you set \code{left}).  This
does not assume that g(x)=1 at the truncation point. (2) manually remove
data with distances less than the left truncation distance -- effectively
move the centre line out to be the truncation distance (this needs to be
done before calling \code{ds}). This then assumes that detection is certain at
the left truncation distance. The former strategy has a weaker assumption,
but will give higher variance as the detection function close to the line
has no data to tell it where to fit -- it will be relying on the data from
after the left truncation point and the assumed shape of the detection
function. The latter is most appropriate in the case of aerial surveys,
where some area under the plane is not visible to the observers, but their
probability of detection is certain at the smallest distance.

}

\section{Monotonicity}{


When adjustment terms are used, it is possible for the detection function to
not always decrease with increasing distance. This is unrealistic and can
lead to bias. To avoid this, the detection function can be constrained for
monotonicity (and is by default for detection functions without covariates).

Monotonicity constraints are supported in a similar way to that described
in Buckland et al (2001). 20 equally spaced points over the range of the
detection function (left to right truncation) are evaluated at each round
of the optimisation and the function is constrained to be either always
less than it's value at zero (\code{"weak"}) or such that each value is
less than or equal to the previous point (monotonically decreasing;
\code{"strict"}). See also \code{\link[mrds:check.mono]{check.mono}}.

Even with no monotonicity constraints, checks are still made that the
detection function is monotonic, see \code{\link[mrds:check.mono]{check.mono}}.

}

\section{Data format}{


One can supply \code{data} only to simply fit a detection function. However, if
abundance/density estimates are necessary further information is required.
Either the \code{region_table}, \code{sample_table} and \code{obs_table} \code{data.frame}s can
be supplied or all data can be supplied as a "flat file" in the \code{data}
argument. In this format each row in data has additional information that
would ordinarily be in the other tables. This usually means that there are
additional columns named: \code{Sample.Label}, \code{Region.Label}, \code{Effort} and
\code{Area} for each observation. See \code{\link[Distance]{flatfile}} for an example.

}

\section{Clusters/groups}{


Note that if the data contains a column named \code{size}, cluster size will be
estimated and density/abundance will be based on a clustered analysis of
the data. Setting this column to be \code{NULL} will perform a non-clustered
analysis (for example if "\code{size}" means something else in your dataset).

}

\examples{
\dontrun{
data("duikers")

# Calculates animal availability adjustment factor
trigger_events <- duikers$VideoStartTimesFullDays
avail <- ct_availability(times = trigger_events$time,
                         format = "\%H:\%M", n_bootstrap = 100)

# Estimate density, building multiple models
flat_data <- duikers$DaytimeDistances \%>\%
  dplyr::slice_sample(prop = .2) # sample 20\% of rows

duiker_density <- ct_fit_ds(data = flat_data,
                            estimate = "density",
                            select_model = TRUE,
                            model_params = list(key = list("hn", "hr"),
                                                adjustment = list("cos"),
                                                nadj = list(2, 3),
                                                order = NULL),
                            availability = avail,
                            truncation = list(left = 2, right = 15),
                            field_of_view = 42,
                            n_bootstrap = 2,
                            cutpoints = c(seq(2, 8, 1), 10, 12, 15)
)

# View density
duiker_density$density
}

}
\references{
Buckland, S.T., Anderson, D.R., Burnham, K.P., Laake, J.L., Borchers, D.L.,
and Thomas, L. (2001). Distance Sampling. Oxford University Press. Oxford, UK.

Howe, E. J., Buckland, S. T., Després-Einspenner, M., & Kühl, H. S. (2017).
Distance sampling with camera traps. Methods in Ecology and Evolution, 8(11),
1558-1565. \doi{10.1111/2041-210X.12790}

Howe, E. J., Buckland, S. T., Després‐Einspenner, M., & Kühl, H. S. (2019).
Model selection with overdispersed distance sampling data. Methods in Ecology and Evolution,
10(1), 38–47.  \doi{10.1111/2041-210X.13082}

Rowcliffe, J. M., Kays, R., Kranstauber, B., Carbone, C., & Jansen, P. A. (2014).
Quantifying levels of animal activity using camera trap data.
Methods in Ecology and Evolution, 5(11), 1170–1179.  \doi{10.1111/2041-210X.12278}
}
\seealso{
\code{\link[=ct_availability]{ct_availability()}}, \code{\link[=ct_select_model]{ct_select_model()}}, \code{\link[=ct_QAIC]{ct_QAIC()}}, \code{\link[=ct_chi2_select]{ct_chi2_select()}}
}
